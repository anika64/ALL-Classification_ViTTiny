{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
    
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kA9QTskA3pS8",
        "outputId": "71c59122-8f07-44a2-9ac4-3ad2472c608e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q datasets accelerate scikit-learn\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXEFEEOk3rWS",
        "outputId": "be5a242d-398d-4ded-d9d7-91142fdc6509"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m125.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m88.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m57.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m43.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m73.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y transformers\n",
        "!pip install transformers --upgrade --no-cache-dir\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YUtmBiZa4BEd",
        "outputId": "8a96179d-9fc7-4ef1-aff6-df78eea61be4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: transformers 4.52.4\n",
            "Uninstalling transformers-4.52.4:\n",
            "  Successfully uninstalled transformers-4.52.4\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.52.4-py3-none-any.whl.metadata (38 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.32.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
            "Downloading transformers-4.52.4-py3-none-any.whl (10.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.5/10.5 MB\u001b[0m \u001b[31m149.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: transformers\n",
            "Successfully installed transformers-4.52.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "print(transformers.__version__)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PPHJ7T454aZv",
        "outputId": "89043a48-6d5c-4fd7-f238-c18d5b4e6c45"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.52.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile, os\n",
        "\n",
        "data_dir = '/content/data'\n",
        "os.makedirs(data_dir, exist_ok=True)\n",
        "\n",
        "fold_0_path = \"/content/drive/MyDrive/fold_0.zip\"\n",
        "val_images_path = \"/content/drive/MyDrive/val_images.zip\"\n",
        "csv_path = \"/content/drive/MyDrive/C-NMC_test_prelim_phase_data_labels.csv\"\n",
        "\n",
        "with zipfile.ZipFile(fold_0_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(os.path.join(data_dir, 'train'))\n",
        "\n",
        "with zipfile.ZipFile(val_images_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(os.path.join(data_dir, 'val'))\n"
      ],
      "metadata": {
        "id": "e3dFCMv23tud"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import glob\n",
        "\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "def find_image_path(filename, folder):\n",
        "    matches = glob.glob(f\"{folder}/**/{filename}\", recursive=True)\n",
        "    return matches[0] if matches else None\n",
        "\n",
        "df[\"file_path\"] = df[\"new_names\"].apply(\n",
        "    lambda name: find_image_path(name, os.path.join(data_dir, 'train')) or\n",
        "                 find_image_path(name, os.path.join(data_dir, 'val'))\n",
        ")\n",
        "\n",
        "df = df.dropna(subset=[\"file_path\"])\n",
        "df = df.rename(columns={\"labels\": \"label\"})\n"
      ],
      "metadata": {
        "id": "gsxEEif133cA"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract subject_id from Patient_ID or file_path\n",
        "df[\"subject_id\"] = df[\"Patient_ID\"].str.extract(r\"UID_([A-Za-z0-9]+)_\")\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "unique_subjects = df[\"subject_id\"].unique()\n",
        "train_subjects, test_subjects = train_test_split(unique_subjects, test_size=0.2, random_state=42)\n",
        "\n",
        "train_df = df[df[\"subject_id\"].isin(train_subjects)].reset_index(drop=True)\n",
        "test_df = df[df[\"subject_id\"].isin(test_subjects)].reset_index(drop=True)\n"
      ],
      "metadata": {
        "id": "B5qCWbQ24to8"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "\n",
        "train_dataset = Dataset.from_pandas(train_df)\n",
        "test_dataset = Dataset.from_pandas(test_df)\n",
        "\n",
        "hf_dataset = {\"train\": train_dataset, \"test\": test_dataset}\n"
      ],
      "metadata": {
        "id": "sWwyt_sH39Si"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoImageProcessor\n",
        "\n",
        "processor = AutoImageProcessor.from_pretrained(\"WinKawaks/vit-tiny-patch16-224\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118,
          "referenced_widgets": [
            "ad1fb3398b2e45499fbcb1ad069977e7",
            "d3235a1443e34261bbc4220932024260",
            "99e3767a36704f68a3958a3c3d3fb259",
            "240978425c4a4652b68b5e57471eba08",
            "06411534ad944c29922ff7afa16fc84b",
            "a36a31ac419b476cad5b2f226136adba",
            "d3d17497e75e469d962a33dc4af65614",
            "ace1b8eb00b440208c30c1f27ded22ec",
            "278984fa210c41a89dafc747253c1292",
            "d180ea4506e1452ab0d82fe28a8c1283",
            "514bb5e1cfd94f6aa2e7633d813f5c28",
            "d2aab77bc26b46d8a124d8913ce8d4e9",
            "c00695645ec0463c8dc8692fe8919a42",
            "128dd019eb244b79aa1adae41bc61436",
            "d1c9d6c951c54c3d93a14d77194f25a6",
            "8def503e5ec847b78cd56549e5e07809",
            "6bc22a08bb8141419d8369d172affed1",
            "edaf7e920c634539b54ee4932eaef76f",
            "1da77bfcc1ef40e38c61bc02eab4f856",
            "fc8b83e8da984dc5b5a7b993d282a998",
            "69014575e0944724b511055c2d7bf230",
            "86739fcbb7284a0bab6c55ba908d4935"
          ]
        },
        "id": "3K-sDPWd3_sg",
        "outputId": "8b6f5e73-f34d-48f5-efae-89a332b7b48b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "preprocessor_config.json:   0%|          | 0.00/160 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ad1fb3398b2e45499fbcb1ad069977e7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/69.7k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d2aab77bc26b46d8a124d8913ce8d4e9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fast image processor class <class 'transformers.models.vit.image_processing_vit_fast.ViTImageProcessorFast'> is available for this model. Using slow image processor class. To use the fast image processor class set `use_fast=True`.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "def preprocess(example):\n",
        "    image = Image.open(example[\"file_path\"]).convert(\"RGB\")\n",
        "    processed = processor(images=image, return_tensors=\"pt\")\n",
        "    return {\n",
        "        \"pixel_values\": processed[\"pixel_values\"].squeeze(),\n",
        "        \"label\": int(example[\"label\"])\n",
        "    }\n",
        "\n",
        "hf_dataset[\"train\"] = hf_dataset[\"train\"].map(preprocess, remove_columns=hf_dataset[\"train\"].column_names, batched=False)\n",
        "hf_dataset[\"test\"] = hf_dataset[\"test\"].map(preprocess, remove_columns=hf_dataset[\"test\"].column_names, batched=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "0edf7d09fb8b4ac583f46e3f3911aa9b",
            "9c845376c6374d8787fc37c6090cd1c8",
            "5240b9c953b64651b84ebfddfcc1fdb5",
            "a4f46f5c60fa4c48a41deabb972d4a26",
            "8cce9768f80342c79dc55a2767adc3b4",
            "ea36d4e1f0b341669fc4e786a1908916",
            "ef31259b57174752bd3c040a2c329198",
            "3bf4897625e74594b555bf1a4ca44193",
            "e2cffff5b00a490ca096524a35af3d55",
            "4c44214f8b4a443793c86453d4509d53",
            "464ab7f2d18a477cbbb75b0378b70966",
            "a3b5fb6f5b46468abf9f62acbbf8127b",
            "c60f0d39a0244c45ae0cd7de4fd23d8f",
            "b2ba4823269f4dbb84a264b638a3545e",
            "c103771eb32d43018c9b58196ad68849",
            "d3a428b0b45e4c8693fc6a202c582df0",
            "f591864088e849778f809f85bff15894",
            "201c925613bc4a7b951a3530944dab7b",
            "7dfec50cd27f4e8e9c189909a5f7b996",
            "812c3f68e90d4ebe92e355831dd4dee9",
            "a87e531b48d64827a04ff78ccbfd735f",
            "942ad45d1deb4bd9950e64ddb3fef81c"
          ]
        },
        "id": "tAOE1G0u416B",
        "outputId": "86347a03-6f6e-4d50-afce-5711e58dc426"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1334 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0edf7d09fb8b4ac583f46e3f3911aa9b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/533 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a3b5fb6f5b46468abf9f62acbbf8127b"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForImageClassification\n",
        "\n",
        "model = AutoModelForImageClassification.from_pretrained(\n",
        "    \"WinKawaks/vit-tiny-patch16-224\",\n",
        "    num_labels=2,\n",
        "    ignore_mismatched_sizes=True\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137,
          "referenced_widgets": [
            "5c6bdd689b784d8eb3ae88290e15ede8",
            "e7b4439229ba4c82b071383d9e38c1f1",
            "b85cafeb6c13412aa43a03a5469625b8",
            "af971bf6d15448429ffc200160193f55",
            "5daccd251529469da752c0a6aefdc3ea",
            "0da0ceef1d214bfea6ff12f2b01702ed",
            "60a193f7aa57491daf13a61b57b7f5e5",
            "a2c45540ba63451f952d27ac4f0ae973",
            "846644f899394035ac63ce9aad5cbd45",
            "bb09e649788a41a8a5e8ed4060613a0e",
            "44ff8486e36245c5982719f59c0a065b"
          ]
        },
        "id": "XjzbPpeR5LWn",
        "outputId": "ce441a3b-8f5a-457c-f39a-92c025a8f008"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/22.9M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5c6bdd689b784d8eb3ae88290e15ede8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of ViTForImageClassification were not initialized from the model checkpoint at WinKawaks/vit-tiny-patch16-224 and are newly initialized because the shapes did not match:\n",
            "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
            "- classifier.weight: found shape torch.Size([1000, 192]) in the checkpoint and torch.Size([2, 192]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    per_device_train_batch_size=8,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    save_total_limit=1,  # Keep only the best checkpoint\n",
        "    load_best_model_at_end=True,  # <-- this loads the best model automatically\n",
        "    metric_for_best_model=\"accuracy\",\n",
        "    greater_is_better=True,\n",
        "    num_train_epochs=10,\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=10,\n",
        "    fp16=True\n",
        ")\n"
      ],
      "metadata": {
        "id": "jStsW7yb5U8Q"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer, EarlyStoppingCallback\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    preds = np.argmax(logits, axis=1)\n",
        "    return {\"accuracy\": accuracy_score(labels, preds)}\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=hf_dataset[\"train\"],\n",
        "    eval_dataset=hf_dataset[\"test\"],\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
        ")\n",
        "\n",
        "trainer.train()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "id": "uMM1VxQ65cB8",
        "outputId": "c4b7d443-a409-4b57-ffb6-e80f319b7a71"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='668' max='1670' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 668/1670 12:11 < 18:20, 0.91 it/s, Epoch 4/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.443200</td>\n",
              "      <td>1.301764</td>\n",
              "      <td>0.733583</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.305800</td>\n",
              "      <td>0.865163</td>\n",
              "      <td>0.857411</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.287100</td>\n",
              "      <td>0.725183</td>\n",
              "      <td>0.838649</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.103800</td>\n",
              "      <td>1.646860</td>\n",
              "      <td>0.776735</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=668, training_loss=0.19212572454304253, metrics={'train_runtime': 733.2812, 'train_samples_per_second': 18.192, 'train_steps_per_second': 2.277, 'total_flos': 2.6625702852919296e+16, 'train_loss': 0.19212572454304253, 'epoch': 4.0})"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained(\"/content/drive/MyDrive/vit-tiny-leukemia\")\n",
        "processor.save_pretrained(\"/content/drive/MyDrive/vit-tiny-leukemia\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddzJy6gH8_c5",
        "outputId": "60f3f377-f898-4e21-9ad0-81a95357417c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/vit-tiny-leukemia/preprocessor_config.json']"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "model.eval().cuda()  # Make sure model is on GPU\n",
        "\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "for example in hf_dataset[\"test\"]:\n",
        "    pixel_values = torch.tensor(example[\"pixel_values\"]).unsqueeze(0).half().cuda()  # Move input to GPU + match precision\n",
        "    with torch.no_grad():\n",
        "        outputs = model(pixel_values=pixel_values)\n",
        "        pred = torch.argmax(outputs.logits, dim=1).item()\n",
        "\n",
        "    all_preds.append(pred)\n",
        "    all_labels.append(example[\"label\"])\n",
        "\n",
        "print(classification_report(all_labels, all_preds, target_names=[\"HEM\", \"ALL\"], digits=2))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9XooFRA9DB1",
        "outputId": "dbe8f552-2e4f-45bf-db47-f5189a3005cc"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         HEM       0.61      0.43      0.51        90\n",
            "         ALL       0.89      0.94      0.92       443\n",
            "\n",
            "    accuracy                           0.86       533\n",
            "   macro avg       0.75      0.69      0.71       533\n",
            "weighted avg       0.84      0.86      0.85       533\n",
            "\n"
          ]
        }
      ]
    }
  ]
}